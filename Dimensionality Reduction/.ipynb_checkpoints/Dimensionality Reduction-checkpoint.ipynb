{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimensionality** - no. of independent features/variables in a dataset\n",
    "\n",
    "Dataset with more than 10 is considered to have **high dimensionality**\n",
    "\n",
    "High Dimensionality:\n",
    "\n",
    "- Increases complexity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Why Reduce Dimensionality?](why_reduce_dimensionality.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dimesionality Reduction:**\n",
    "- Feature Selection\n",
    "\n",
    "The selected features remain unchanged, and are therefore easy to interpret.\n",
    "- Feature Extraction\n",
    "\n",
    "![Feature Selection and Feature Extraction](feature_selection_extraction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Remove features with little/no variance**\n",
    "\n",
    "This is because they contain little information that could be used. Mostly in classification problems.\n",
    "\n",
    "Features with no variance have:\n",
    "- Std of 0 or approaching 0\n",
    "- Min and Max value is same or almost same\n",
    "\n",
    "Ways to identify features with no variance:\n",
    "- Use .describe on the dataset.\n",
    "- Plot numeric features using pairplot (Good for small to medium sized dimensionality)\n",
    "- Using Variance Threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Remove highly correlated features/redundant features**\n",
    "\n",
    "Ways to identify highly correlated features:\n",
    "- Plot numeric features using pairplot (Good for small to medium sized dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Remove features with null values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visually detecting redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot and color the points using the 'Gender' feature\n",
    "sns.pairplot(ansur_df_1, hue='Gender', diag_kind='hist')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Remove one of the redundant features\n",
    "reduced_df = ansur_df_1.drop('stature_m', 1)\n",
    "\n",
    "# Create a pairplot and color the points using the 'Gender' feature\n",
    "sns.pairplot(reduced_df, hue='Gender')\n",
    "\n",
    "# Remove the feature with no variance\n",
    "reduced_df = ansur_df_2.drop('n_legs', 1)\n",
    "\n",
    "# Create a pairplot and color the points using the 'Gender' feature\n",
    "sns.pairplot(reduced_df, hue='Gender', diag_kind='hist')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE visualization of high-dimensional data\n",
    "\n",
    "Helps us explore interesting patterns in the dataset.\n",
    "\n",
    "Doesn't work with non-numeric data. Encode non-numeric data or drop them.\n",
    "\n",
    "Use it when you want to visually explore the patterns in a high dimensional dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-numerical columns in the dataset\n",
    "non_numeric = ['Branch', 'Gender', 'Component']\n",
    "\n",
    "# Drop the non-numerical columns from df\n",
    "df_numeric = df.drop(non_numeric, axis=1)\n",
    "\n",
    "# Create a t-SNE model with learning rate 50\n",
    "m = TSNE(learning_rate=50)\n",
    "\n",
    "# Fit and transform the t-SNE model on the numeric dataset\n",
    "tsne_features = m.fit_transform(df_numeric)\n",
    "print(tsne_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code reduced the numeric columns from 90 to just 2 which can easily be plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the output of t-SNE dimensionality reduction on the combined male and female Ansur dataset. You'll create 3 scatterplots of the 2 t-SNE features ('x' and 'y') which were added to the dataset df. In each scatterplot you'll color the points according to a different categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color the points by Army Component\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue='Component', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Color the points by Army Branch\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue='Branch', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Color the points by Gender\n",
    "sns.scatterplot(x=\"x\", y=\"y\", hue='Gender', data=df)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curse of Dimensionality\n",
    "\n",
    "Models tend to overfit on data of high dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If accuracy on train set is more than accuracy on test set then the model did not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid overfitting, no. of observations should increase exponentially with no. of features added to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select the Gender column as the feature to be predicted (y)\n",
    "y = ansur_df['Gender']\n",
    "\n",
    "# Remove the Gender column to create the training data\n",
    "X = ansur_df.drop('Gender', 1)\n",
    "\n",
    "# Perform a 70% train and 30% test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(\"{} rows in test set vs. {} in training set. {} Features.\".format(X_test.shape[0], X_train.shape[0], X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SVC from sklearn.svm and accuracy_score from sklearn.metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an instance of the Support Vector Classification class\n",
    "svc = SVC()\n",
    "\n",
    "# Fit the model to the training data\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy scores on both train and test data\n",
    "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
    "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of the above code:\n",
    "49.7% accuracy on test set vs. 100.0% on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll reduce the overfit with the help of dimensionality reduction. In this case, you'll apply a rather drastic form of dimensionality reduction by only selecting a single column that has some good information to distinguish between genders. You'll repeat the train-test split, model fit and prediction steps to compare the accuracy on test vs. training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign just the 'neckcircumferencebase' column from ansur_df to X\n",
    "X = ansur_df[['neckcircumferencebase']]\n",
    "\n",
    "# Split the data, instantiate a classifier and fit the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy scores on both train and test data\n",
    "accuracy_train = accuracy_score(y_train, svc.predict(X_train))\n",
    "accuracy_test = accuracy_score(y_test, svc.predict(X_test))\n",
    "\n",
    "print(\"{0:.1%} accuracy on test set vs. {1:.1%} on training set\".format(accuracy_test, accuracy_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of the above code:\n",
    "49.7% accuracy on test set vs. 100.0% on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Featues with little variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box plots help visualize differences in mean, median, variance of numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "head_df.boxplot()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization would be done to ensure the features are comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "normalized_df = head_df / head_df.mean()\n",
    "\n",
    "normalized_df.boxplot()\n",
    "plt.show()\n",
    "\n",
    "print(normalized_df.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output from the code above.\n",
    "\n",
    "headbreadth          1.678952e-03\n",
    "headcircumference    1.029623e-03\n",
    "headlength           1.867872e-03\n",
    "tragiontopofhead     2.639840e-03\n",
    "n_hairs              1.002552e-08\n",
    "measurement_error    3.231707e-27\n",
    "\n",
    "Inspect the printed variances. If you want to remove the 2 very low variance features. What would be a good variance threshold?\n",
    "\n",
    "Ans: 1.0e-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You established that 0.001 is a good threshold to filter out low variance features in head_df after normalization. Now use the VarianceThreshold feature selector to remove these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing low variance features using Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Create a VarianceThreshold feature selector\n",
    "sel = VarianceThreshold(threshold=0.001)\n",
    "\n",
    "# Fit the selector to normalized head_df\n",
    "sel.fit(head_df / head_df.mean())\n",
    "\n",
    "# Create a boolean mask\n",
    "mask = sel.get_support()\n",
    "\n",
    "# Apply the mask to create a reduced dataframe\n",
    "reduced_df = head_df.loc[:, mask]\n",
    "\n",
    "print(\"Dimensionality reduced from {} to {}.\".format(head_df.shape[1], reduced_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduced from 6 to 4 due to the above code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Featues with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask on whether each feature has less than 50% missing values.\n",
    "mask = school_df.isna().sum() / len(school_df) < 0.5\n",
    "\n",
    "# Create a reduced dataset by applying the mask\n",
    "reduced_df = school_df.loc[:, mask]\n",
    "\n",
    "print(school_df.shape)\n",
    "print(reduced_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise Correlation\n",
    "![Correlation Coefficient](correlation_coefficient.png)\n",
    "![Correlation Coefficient](correlation_coefficient_plotted.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation of A to B = Correlation of B to A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansur_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the correlation matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix\n",
    "corr = ansur_df.corr()\n",
    "\n",
    "# Draw the heatmap\n",
    "sns.heatmap(corr,  cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a boolean mask for the upper triangle of the plot and the mask to the heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation matrix\n",
    "corr = ansur_df.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle \n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Add the mask to the heatmap\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=1, annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing highly correlated features\n",
    "\n",
    "Highly correlated features do not bring new information but increase complexity.\n",
    "\n",
    "Remove one of the 2 features with a high correlation.\n",
    "\n",
    "Incase numerous features represent the same measurement, remove all but one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Caveats\n",
    "\n",
    "There's need to visually inspect correlated features to avoid surprises like the one below.\n",
    "\n",
    "![Anscombe's Quartet](correlation_caveats_anscombe.png)\n",
    "\n",
    "Correlation does not imply causation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering out highly correlated features\n",
    "\n",
    "You're going to automate the removal of highly correlated features in the numeric ANSUR dataset. You'll calculate the correlation matrix and filter out columns that have a correlation coefficient of more than 0.95 or less than -0.95.\n",
    "\n",
    "Since each correlation coefficient occurs twice in the matrix (correlation of A to B equals correlation of B to A) you'll want to ignore half of the correlation matrix so that only one of the two correlated features is removed. Use a mask trick for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix and take the absolute value\n",
    "corr_matrix = ansur_df.corr().abs()\n",
    "\n",
    "# Create a True/False mask and apply it\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "tri_df = corr_matrix.mask(mask)\n",
    "\n",
    "# List column names of highly correlated features (r > 0.95)\n",
    "to_drop = [c for c in tri_df.columns if any(tri_df[c] >  0.95)]\n",
    "\n",
    "# Drop the features in the to_drop list\n",
    "reduced_df = ansur_df.drop(to_drop, axis=1)\n",
    "\n",
    "print(\"The reduced dataframe has {} columns.\".format(reduced_df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting featues for model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection using Classification Algorithms\n",
    "Get model Coefficients for different features using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on the training features and transform these in one go\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# Fit the logistic regression model on the scaled training data\n",
    "lr.fit(X_train_std, y_train)\n",
    "\n",
    "# Scale the test features\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Predict diabetes presence on the scaled test set\n",
    "y_pred = lr.predict(X_test_std)\n",
    "\n",
    "# Prints accuracy metrics and feature coefficients\n",
    "print(\"{0:.1%} accuracy on test set.\".format(accuracy_score(y_test, y_pred))) \n",
    "print(dict(zip(X.columns, abs(lr.coef_[0]).round(2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination with Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the feature with the lowest coefficient causes the other feature coefficients to change(increase/decrease) hence drop unimportant features one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RFE with a LogisticRegression estimator and 3 features to select\n",
    "rfe = RFE(estimator=LogisticRegression(), n_features_to_select=3, verbose=1)\n",
    "\n",
    "# Fits the eliminator to the data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Print the features and their ranking (high = dropped early on)\n",
    "print(dict(zip(X.columns, rfe.ranking_)))\n",
    "\n",
    "# Print the features that are not eliminated\n",
    "print(X.columns[rfe.support_])\n",
    "\n",
    "# Calculates the test set accuracy\n",
    "acc = accuracy_score(y_test, rfe.predict(X_test))\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output of the above code:\n",
    "\n",
    "{'age': 1, 'insulin': 4, 'triceps': 3, 'pregnant': 5, 'glucose': 1, 'bmi': 1, 'family': 2, 'diastolic': 6}\n",
    "\n",
    "Index(['glucose', 'bmi', 'age'], dtype='object')\n",
    "\n",
    "80.6% accuracy on test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Based Feature Selection\n",
    "\n",
    "Some models perform feature selection by design to avoid overfitting e.g **RandomForestClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a 75% training and 25% test data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Fit the random forest model to the training data\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy\n",
    "acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "\n",
    "# Print the importances per feature\n",
    "print(dict(zip(X.columns, rf.feature_importances_.round(2))))\n",
    "\n",
    "# Print accuracy\n",
    "print(\"{0:.1%} accuracy on test set.\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output for the above code:\n",
    "\n",
    "{'age': 0.16, 'insulin': 0.13, 'triceps': 0.11, 'pregnant': 0.09, 'glucose': 0.21, 'bmi': 0.09, 'family': 0.12, 'diastolic': 0.08}\n",
    "\n",
    "77.6% accuracy on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the fitted random model to select the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for features importances above the threshold\n",
    "mask = rf.feature_importances_ > 0.15\n",
    "\n",
    "# Prints out the mask\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sub-select the most important features by applying the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask for features importances above the threshold\n",
    "mask = rf.feature_importances_ > 0.15\n",
    "\n",
    "# Apply the mask to the feature dataset X\n",
    "reduced_X = X.loc[:, mask]\n",
    "\n",
    "# prints out the selected column names\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recurcive Feature Elimination with Random Forest Classifier\n",
    "\n",
    "This method is more conservative compared to selecting features after applying a single importance threshold. Since dropping one feature can influence the relative importances of the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the feature eliminator around the random forest model\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=2, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Create a mask using an attribute of rfe\n",
    "mask = rfe.support_\n",
    "\n",
    "# Apply the mask to the feature dataset X and print the result\n",
    "reduced_X = X.loc[:, mask]\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the settings of RFE() to eliminate 2 features at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the feature eliminator to remove 2 features on each step\n",
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=2, step = 2, verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Create a mask\n",
    "mask = rfe.support_\n",
    "\n",
    "# Apply the mask to the feature dataset X and print the result\n",
    "reduced_X = X.loc[:, mask]\n",
    "print(reduced_X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection using Regression Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the test size to 30% to get a 70-30% train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Fit the scaler on the training features and transform these in one go\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "\n",
    "# Create the Lasso model\n",
    "la = Lasso()\n",
    "\n",
    "# Fit it to the standardized training data\n",
    "la.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lasso model results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test set with the pre-fitted scaler\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "# Calculate the coefficient of determination (R squared) on X_test_std\n",
    "r_squared = la.score(X_test_std, y_test)\n",
    "print(\"The model can predict {0:.1%} of the variance in the test set.\".format(r_squared))\n",
    "\n",
    "# Create a list that has True values when coefficients equal 0\n",
    "zero_coef = la.coef_ == 0\n",
    "\n",
    "# Calculate how many features have a zero coefficient\n",
    "n_ignored = sum(zero_coef)\n",
    "print(\"The model has ignored {} out of {} features.\".format(n_ignored, len(la.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adjusting the regularization strength**\n",
    "\n",
    "Your current Lasso model has an R2 score of 84.7%. When a model applies overly powerful regularization it can suffer from high bias, hurting its predictive power.\n",
    "\n",
    "Let's improve the balance between predictive power and model simplicity by tweaking the alpha parameter.\n",
    "\n",
    "Find the highest value for alpha that gives an R2 value above 98% from the options: 1, 0.5, 0.1, and 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the highest alpha value with R-squared above 98%\n",
    "la = Lasso(alpha=0.1, random_state=0)\n",
    "\n",
    "# Fits the model and calculates performance stats\n",
    "la.fit(X_train_std, y_train)\n",
    "r_squared = la.score(X_test_std, y_test)\n",
    "n_ignored_features = sum(la.coef_ == 0)\n",
    "\n",
    "# Print peformance stats \n",
    "print(\"The model can predict {0:.1%} of the variance in the test set.\".format(r_squared))\n",
    "print(\"{} out of {} features were ignored.\".format(n_ignored_features, len(la.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this more appropriate regularization strength we can predict 98% of the variance in the BMI value while ignoring 2/3 of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best value for alpha can be a tedious process. Use Cross Validation to achieve that i.e use LassoCV instead. It gets the best value for alpha and uses it to fit the model. .alha_ method gives the best value for alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining feature selectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Create and fit the LassoCV model on the training set\n",
    "lcv = LassoCV()\n",
    "lcv.fit(X_train, y_train)\n",
    "print('Optimal alpha = {0:.3f}'.format(lcv.alpha_))\n",
    "\n",
    "# Calculate R squared on the test set\n",
    "r_squared = lcv.score(X_test, y_test)\n",
    "print('The model explains {0:.1%} of the test set variance'.format(r_squared))\n",
    "\n",
    "# Create a mask for coefficients not equal to zero\n",
    "lcv_mask = lcv.coef_ != 0\n",
    "print('{} features out of {} selected'.format(sum(lcv_mask), len(lcv_mask)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "\n",
    "Optimal alpha = 0.089\n",
    "\n",
    "The model explains 88.2% of the test set variance\n",
    "\n",
    "26 features out of 32 selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with RandomForest (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Select 10 features with RFE on a RandomForestRegressor, drop 3 features on each step\n",
    "rfe_rf = RFE(estimator=RandomForestRegressor(), \n",
    "             n_features_to_select=10, step=3, verbose=1)\n",
    "rfe_rf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the R squared on the test set\n",
    "r_squared = rfe_rf.score(X_test, y_test)\n",
    "print('The model can explain {0:.1%} of the variance in the test set'.format(r_squared))\n",
    "\n",
    "# Assign the support array to gb_mask\n",
    "rf_mask = rfe_rf.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "    \n",
    "Fitting estimator with 32 features.\n",
    "\n",
    "Fitting estimator with 29 features.\n",
    "\n",
    "Fitting estimator with 26 features.\n",
    "\n",
    "Fitting estimator with 23 features.\n",
    "\n",
    "Fitting estimator with 20 features.\n",
    "\n",
    "Fitting estimator with 17 features.\n",
    "\n",
    "Fitting estimator with 14 features.\n",
    "\n",
    "Fitting estimator with 11 features.\n",
    "\n",
    "The model can explain 84.0% of the variance in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection with GradientBoosting (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Select 10 features with RFE on a GradientBoostingRegressor, drop 3 features on each step\n",
    "rfe_gb = RFE(estimator=GradientBoostingRegressor(), \n",
    "             n_features_to_select=10, step=3, verbose=1)\n",
    "rfe_gb.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the R squared on the test set\n",
    "r_squared = rfe_gb.score(X_test, y_test)\n",
    "print('The model can explain {0:.1%} of the variance in the test set'.format(r_squared))\n",
    "\n",
    "# Assign the support array to gb_mask\n",
    "gb_mask = rfe_gb.support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "    \n",
    "Fitting estimator with 32 features.\n",
    "\n",
    "Fitting estimator with 29 features.\n",
    "\n",
    "Fitting estimator with 26 features.\n",
    "\n",
    "Fitting estimator with 23 features.\n",
    "\n",
    "Fitting estimator with 20 features.\n",
    "\n",
    "Fitting estimator with 17 features.\n",
    "\n",
    "Fitting estimator with 14 features.\n",
    "\n",
    "\n",
    "Fitting estimator with 11 features.\n",
    "\n",
    "The model can explain 85.6% of the variance in the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the above Feature Selectors\n",
    "\n",
    "We'll combine the votes of the 3 models you built in the previously, to decide which features are important into a meta mask. \n",
    "\n",
    "We'll then use this mask to reduce dimensionality and see how a simple linear regressor performs on the reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the votes of the three models\n",
    "votes = np.sum([lcv_mask, rf_mask, gb_mask], axis=0)\n",
    "\n",
    "# Create a mask for features selected by all 3 models\n",
    "meta_mask = votes >= 3\n",
    "\n",
    "# Apply the dimensionality reduction on X\n",
    "X_reduced = X.loc[:, meta_mask]\n",
    "\n",
    "# Plug the reduced dataset into a linear regression pipeline\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.3, random_state=0)\n",
    "lm.fit(scaler.fit_transform(X_train), y_train)\n",
    "r_squared = lm.score(scaler.transform(X_test), y_test)\n",
    "print('The model can explain {0:.1%} of the variance in the test set using {1:} features.'.format(r_squared, len(lm.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "\n",
    "The model can explain 86.8% of the variance in the test set using 7 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Manual Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean height\n",
    "height_df['height'] = height_df[['height_1', 'height_2', 'height_3']].mean(axis=1)\n",
    "\n",
    "# Drop the 3 original height features\n",
    "reduced_df = height_df.drop(['height_1', 'height_2', 'height_3'], axis=1)\n",
    "\n",
    "print(reduced_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA-Principal Components Analysis\n",
    "\n",
    "![PCA intuition](pca_intuition.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2 perpendicular vectors above are aligned with the variance of the data.\n",
    "\n",
    "- People with a positive component for the red vector have both long forearms and long upper arms.\n",
    "\n",
    "- People with a negative component for the red vector have short forearms and short upper arms.\n",
    "\n",
    "- People with a positive component for the yellow vector have long upper arms relative to their forearms.\n",
    "\n",
    "- People with a negative component for the yellow vector have long forearms relative to their upper arms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA intuition](pca_concept_coordinates.png) \n",
    "![PCA intuition](pca_concept_components.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A point at coordinates(2.7, 1) can be described in terms of the vectors i.e 2 times the red vector and -1 times the yellow vector.\n",
    "\n",
    "2 and -1 become the 1st and 2nd principal components respectively. \n",
    "\n",
    "The 1st one is most important as it is aligned with the most source of variance in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The component do not have duplicate information and are ranked from most important to least important.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PCA correlation](pca_correlation.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a dataset with very high correlation, most of the variance will be explained in the 1st few components.\n",
    "\n",
    "In the above diagram, PC1 explains 90% of the variance. It would thus make sence to drop the 2PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually inspect a 4 feature sample of the ANSUR dataset before and after PCA using Seaborn's pairplot(). \n",
    "\n",
    "This will allow you to inspect the pairwise correlations between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot of the principal component dataframe\n",
    "sns.pairplot(ansur_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create the scaler\n",
    "scaler = StandardScaler()\n",
    "ansur_std = scaler.fit_transform(ansur_df)\n",
    "\n",
    "# Create the PCA instance and fit and transform the data with pca\n",
    "pca = PCA()\n",
    "pc = pca.fit_transform(ansur_std)\n",
    "pc_df = pd.DataFrame(pc, columns=['PC 1', 'PC 2', 'PC 3', 'PC 4'])\n",
    "\n",
    "# Create a pairplot of the principal component dataframe\n",
    "sns.pairplot(pc_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA on a somewhat larger ANSUR datasample with 13 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create the scaler\n",
    "scaler = StandardScaler()\n",
    "ansur_std = scaler.fit_transform(ansur_df)\n",
    "\n",
    "# Create the PCA instance and fit and transform the data with pca\n",
    "pca = PCA()\n",
    "pca = pca.fit(ansur_std)\n",
    "\n",
    "# Inspect the explained variance ratio per component\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the cumulative sum of the explained variance ratio\n",
    "print(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to understand Principal Components.\n",
    "\n",
    "![pca components](pca_components.png)\n",
    "\n",
    "**pca.components_** tells us to what extent each component vector is affected by a particular feature in the dataset.\n",
    "\n",
    "Feature with the biggest positive or negative effect on a component can be used to add meaning to that component.\n",
    "\n",
    "PC1 above is affected by both hand and foot length.\n",
    "\n",
    "PC2 people with shorter hands and longer feet score high for PC2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA to the numeric features of the Pokemon dataset, poke_df, using a pipeline to combine the feature scaling and PCA in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "        \t\t ('reducer', PCA(n_components=2))])\n",
    "\n",
    "# Fit it to the dataset and extract the component vectors\n",
    "pipe.fit(poke_df)\n",
    "vectors = pipe.steps[1][1].components_.round(2)\n",
    "\n",
    "# Print feature effects\n",
    "print('PC 1 effects = ' + str(dict(zip(poke_df.columns, vectors[0]))))\n",
    "print('PC 2 effects = ' + str(dict(zip(poke_df.columns, vectors[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "\n",
    "PC 1 effects = {'Sp. Atk': 0.46, 'Sp. Def': 0.45, 'Defense': 0.36, 'Attack': 0.44, 'Speed': 0.34, 'HP': 0.39}\n",
    "PC 2 effects = {'Sp. Atk': -0.31, 'Sp. Def': 0.24, 'Defense': 0.63, 'Attack': -0.01, 'Speed': -0.67, 'HP': 0.08}\n",
    "\n",
    "All features have a similar positive effect. PC 1 can be interpreted as a measure of overall quality (high stats).\n",
    "\n",
    "Defense has a strong positive effect on the second component and speed a strong negative one. This component quantifies an agility vs. armor & protection trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the PCA pipeline you've built in the previously to visually explore how some categorical features relate to the variance in poke_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('reducer', PCA(n_components=2))])\n",
    "\n",
    "# Fit the pipeline to poke_df and transform the data\n",
    "pc = pipe.fit_transform(poke_df)\n",
    "\n",
    "# Add the 2 components to poke_cat_df\n",
    "poke_cat_df['PC 1'] = pc[:, 0]\n",
    "poke_cat_df['PC 2'] = pc[:, 1]\n",
    "\n",
    "# Use the Type feature to color the PC 1 vs PC 2 scatterplot\n",
    "sns.scatterplot(data=poke_cat_df, \n",
    "                x='PC 1', y='PC 2', hue='Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Legendary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('reducer', PCA(n_components=2))])\n",
    "\n",
    "# Fit the pipeline to poke_df and transform the data\n",
    "pc = pipe.fit_transform(poke_df)\n",
    "\n",
    "# Add the 2 components to poke_cat_df\n",
    "poke_cat_df['PC 1'] = pc[:, 0]\n",
    "poke_cat_df['PC 2'] = pc[:, 1]\n",
    "\n",
    "# Use the Type feature to color the PC 1 vs PC 2 scatterplot\n",
    "sns.scatterplot(data=poke_cat_df, \n",
    "                x='PC 1', y='PC 2', hue='Legendary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reducer', PCA(n_components=2)),\n",
    "        ('classifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Prints the explained variance ratio\n",
    "print(pipe.steps[1][1].explained_variance_ratio_)\n",
    "\n",
    "# Score the accuracy on the test set\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "# Prints the model accuracy\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the above code:\n",
    "\n",
    "[0.45624044 0.17767414]\n",
    "\n",
    "95.8% test set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat above with 3 PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the pipeline\n",
    "pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reducer', PCA(n_components=3)),\n",
    "        ('classifier', RandomForestClassifier(random_state=0))])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Score the accuracy on the test set\n",
    "accuracy = pipe.score(X_test, y_test)\n",
    "\n",
    "# Prints the explained variance ratio and accuracy\n",
    "print(pipe.steps[1][1].explained_variance_ratio_)\n",
    "print('{0:.1%} test set accuracy'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the code above:\n",
    "\n",
    "[0.45624044 0.17767414 0.12858833]\n",
    "\n",
    "95.0% test set accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the proportion of variance to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipe a scaler to PCA selecting 80% of the variance\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "        \t\t ('reducer', PCA(n_components=0.8))])\n",
    "\n",
    "# Fit the pipe to the data\n",
    "pipe.fit(ansur_df)\n",
    "\n",
    "print('{} components selected'.format(len(pipe.steps[1][1].components_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output for the code above:\n",
    "\n",
    "11 components selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the number of components to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline a scaler and pca selecting 10 components\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "        \t\t ('reducer', PCA(n_components=10))])\n",
    "\n",
    "# Fit the pipe to the data\n",
    "pipe.fit(ansur_df)\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.plot(pipe.steps[1][1].explained_variance_ratio_)\n",
    "\n",
    "plt.xlabel('Principal component index')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output of the above code:\n",
    "\n",
    "![explained variance plotted](explained_variance_plotted.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To how many components can you reduce the dataset without compromising too much on explained variance?\n",
    "\n",
    "Note that the x-axis is zero indexed.\n",
    "\n",
    "Ans: 3 (the elbow of the curve is at index 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the input data to principal components\n",
    "pc = pipe.transform(X_test)\n",
    "\n",
    "# Inverse transform the components to original feature space\n",
    "X_rebuilt = pipe.inverse_transform(pc)\n",
    "\n",
    "# Prints the number of features\n",
    "print(\"X_rebuilt has {} features\".format(X_rebuilt.shape[1]))\n",
    "\n",
    "# Plot the reconstructed data\n",
    "plot_digits(X_rebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
